{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_module.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMWr6o6V33RymV1eJSh3r86",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tenoriolms/databank_CH4/blob/main/_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.python.org/pt-br/3/tutorial/modules.html"
      ],
      "metadata": {
        "id": "yhh50b4DO_yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import missingno as msno\n",
        "\n",
        "\n",
        "import sklearn.metrics"
      ],
      "metadata": {
        "id": "4OBUth-Cre0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import sklearn.datasets\n",
        "import sklearn.model_selection\n",
        "\n",
        "import sklearn.ensemble #bibliotecas de aprendizado de máquina\n",
        "'''"
      ],
      "metadata": {
        "id": "lNstVHDPrkZ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a4c51ff3-b6a2-488a-9e92-dccabc62f14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport sklearn.datasets\\nimport sklearn.model_selection\\n\\nimport sklearn.ensemble #bibliotecas de aprendizado de máquina\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Declaração de Variáveis"
      ],
      "metadata": {
        "id": "OJgsy03zYNiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = '962' #ID do databank\n",
        "git_import_file = '' #nome da variante do databank original\n",
        "data_url = ''\n",
        "\n",
        "\n",
        "#dict para armazenar dados da função ID\n",
        "ID_dict = {}\n",
        "\n",
        "#gases com permeabilidades presentes no banco de dados ordem crescente de kinetic diameter\n",
        "#EM ORDEM CRESCENTE AO D.C., COMO NO DATABANK:\n",
        "gases = ('He','H2','CO2','O2','H2S','N2','CO','CH4','C2H6','SF6') #referentes aos dados de permeabilidade\n",
        "gases_kinetic_diameter = {'He':260,\n",
        "                          'H2':289,\n",
        "                          'CO2':330,\n",
        "                          'Ar':340,\n",
        "                          'O2':346,\n",
        "                          'H2S':360,\n",
        "                          'N2':364,\n",
        "                          'CO':376,\n",
        "                          'CH4':380,\n",
        "                          'C2H6':444.3,\n",
        "                          'SF6':550,\n",
        "                          'none':0}\n",
        "gases_effec_diameter = {'He':178, #T>Tg\n",
        "                        'H2':214,\n",
        "                        'CO2':302,\n",
        "                        'O2':289,\n",
        "                        'Ar':297,\n",
        "                        'H2S':np.nan,\n",
        "                        'N2':304,\n",
        "                        'CO':304,\n",
        "                        'CH4':318,\n",
        "                        'C2H6':346,\n",
        "                        'SF6':np.nan,\n",
        "                        'none':0}\n",
        "gases_molar_mass = {'He':4.00, \n",
        "                    'H2':2.02,\n",
        "                    'CO2':44.01,\n",
        "                    'O2':31.98,\n",
        "                    'Ar':39.95,\n",
        "                    'H2S':34.10,\n",
        "                    'N2':28.00,\n",
        "                    'CO':28.01,\n",
        "                    'CH4':16.04,\n",
        "                    'C2H6':30.07,\n",
        "                    'SF6':146.06,\n",
        "                    'none':0.}\n",
        "gases_polarizability = {'He':0.208, #https://cccbdb.nist.gov/pollistx.asp\n",
        "                        'H2':0.787,\n",
        "                        'CO2':2.507,\n",
        "                        'O2':1.562,\n",
        "                        'Ar':1.664,\n",
        "                        'H2S':3.631,\n",
        "                        'N2':1.710,\n",
        "                        'CO':1.953,\n",
        "                        'CH4':2.448,\n",
        "                        'C2H6':4.226,\n",
        "                        'SF6':4.490,\n",
        "                        'none':0.}\n",
        "\n",
        "\n",
        "gases_kinetic_diameter_inverse = {}\n",
        "for i in gases_kinetic_diameter.keys():\n",
        "  gases_kinetic_diameter_inverse[ gases_kinetic_diameter[i] ] = i\n",
        "\n",
        "gases_effec_diameter_inverse = {}\n",
        "for i in gases_effec_diameter.keys():\n",
        "  gases_effec_diameter_inverse[ gases_effec_diameter[i] ] = i\n",
        "                        \n",
        "#frequencia de dados para cada gas em situação \"pura\" e \"mixtura\"\n",
        "count_pure = {}\n",
        "count_mixture = {}\n",
        "\n",
        "\n",
        "#nome das colunas correspondentes à características da membrana e do processo e \n",
        "#seus respectivos índices na coluna\n",
        "#EM ORDEM:\n",
        "columns_membrane = ['type', 'description', 'support_material', 'subtype', 'filler_loading',\n",
        "                    'previous_thickness', 'mean_thickness', 'mean_pore_size', 'pore_volume',\n",
        "                    'specific_surface_area',  'aging']\n",
        "columns_process = ['surface_area', 'temperature', 'feed_pressure', 'permeate_pressure',\n",
        "                   'delta_pressure', 'feed_flow_rate', 'sweep_gas', 'sweep_gas_flow',\n",
        "                   'stage_cut']\n",
        "columns_others = ['provided_data_type', 'in_reference_data_location', 'reference', 'url']\n",
        "\n",
        "columns_membrane_index = {}\n",
        "columns_process_index = {}\n",
        "columns_others_index = {}\n",
        "\n",
        "#A performance de cada gás foi representada pela seguintes variáveis:\n",
        "prefix1='x_' #Fração mássica/molar/volumétrica\n",
        "prefix2='Py_' #Permeabilidade\n",
        "prefix3='Pe_' #Permeância\n",
        "\n",
        "#VARIÁVEIS AUXILIARES:\n",
        "dados = pd.DataFrame() #Dataframe a ser utilizados para a previsão. Versão refinada."
      ],
      "metadata": {
        "id": "lF5GegZeiqgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GitHub info"
      ],
      "metadata": {
        "id": "7hw5ZX-UrwPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "git_username = 'tenoriolms' #username no GitHub\n",
        "git_repository = 'databank_CH4' #Nome do repositório\n",
        "\n",
        "git_token = 'não pode' #token para acesso do repositório.\n",
        "#O github possui um algoritmo para verificar se dentro de cada arquivo importado/commitado\n",
        "#existe o token de acesso criado, que é secreto. Caso existir, esse token é revogado.\n",
        "#Como esse notebook irá ser exportado para o github. O token não pode ser escrito aqui.\n",
        "\n",
        "!git config --global user.email \"lhucas_tenorio@hotmail.com\"\n",
        "!git config --global user.name \"tenoriolms\""
      ],
      "metadata": {
        "id": "8b3c8hLXgxzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Funções"
      ],
      "metadata": {
        "id": "FCyT9E2Q5mgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ID(index)"
      ],
      "metadata": {
        "id": "vtgMNNwklJU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ID = string utilizada para identificar uma membrana e suas circunstâncias de utilização no banco de dados\n",
        "#A ID é a soma das variáveis (em forma de strings) que podem variar em uma dada referência\n",
        "def ID(i, df):\n",
        "  if i in ID_dict:\n",
        "    return ID_dict[i]\n",
        "  else:\n",
        "    \n",
        "    aux = str(df['description'][i]) + str(df['filler_loading'][i]) \\\n",
        "    + str(df['mean_thickness'][i]) + str(df['mean_pore_size'][i]) \\\n",
        "    + str(df['temperature'][i]) + str(df['feed_pressure'][i]) \\\n",
        "    + str(df['delta_pressure'][i]) + str(df['feed_flow_rate'][i]) \\\n",
        "    + str(df['stage_cut'][i]) + str(df['aging'][i]) \\\n",
        "    + str(df['reference'][i])\n",
        "    ID_dict[i] = aux\n",
        "    \n",
        "    return aux"
      ],
      "metadata": {
        "id": "Dl2BDR83sBUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##get_key(val,my_dict))"
      ],
      "metadata": {
        "id": "bAibWU-Ace4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_key(val,my_dict): #dict = key : value\n",
        "    for key, value in my_dict.items():\n",
        "         if val == value:\n",
        "             return key\n",
        " \n",
        "    return \"get_key function: There is no such Key\""
      ],
      "metadata": {
        "id": "CeZ4uSBD0e8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##submit_file(git_export_file)"
      ],
      "metadata": {
        "id": "g4VQjLibWZFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#exportar para o GitHub\n",
        "def submit_file(git_export_file):\n",
        "  !git clone https://{git_token}@github.com/{git_username}/{git_repository}\n",
        "  !cp {git_export_file} {git_repository}\n",
        "  %cd {git_repository}\n",
        "  !git add {git_export_file}\n",
        "  !git commit -m 'Add/Atualizar arquivo {input_file}'\n",
        "  !git push -u origin\n",
        "  %cd ..\n",
        "  !rm -rf {git_repository}"
      ],
      "metadata": {
        "id": "xDNh_KvisG17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##import_file(git_import_file)"
      ],
      "metadata": {
        "id": "Uy4iamAaehgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importar um arquivo do GitHub\n",
        "def import_file(git_import_file):\n",
        "  !git clone https://{git_token}@github.com/{git_username}/{git_repository}\n",
        "  !cp {git_repository}/{git_import_file} .\n",
        "  !rm -rf {git_repository}"
      ],
      "metadata": {
        "id": "xJnMRW1vsXxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Zscores(df_for_scaled, df_reference)"
      ],
      "metadata": {
        "id": "YTXQNw2ofLyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Escalonar cada coluna utilizando o \"z score\"\n",
        "def Zscores(df_for_scaled, df_reference):\n",
        "  for i in df_for_scaled.columns: \n",
        "    df_for_scaled[i] = (df_for_scaled[i] - df_reference[i].mean()) / df_reference[i].std()     \n",
        "  #return df_for_scaled"
      ],
      "metadata": {
        "id": "eJSvt3-Nn1ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##undo_Zscores(df_scaled, df_reference)"
      ],
      "metadata": {
        "id": "3CZULGDEKYG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#desfazer o escalonamento realizado para cada coluna utilizando o \"z score\"\n",
        "def undo_Zscores(df_scaled, df_reference):\n",
        "  for i in df_scaled.columns:\n",
        "    df_scaled[i] = df_scaled[i]*df_reference[i].std() + df_reference[i].mean()\n",
        "  #return df_scaled"
      ],
      "metadata": {
        "id": "yvtWO85roBUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##str2int_simple_encoder(df,columns='all')"
      ],
      "metadata": {
        "id": "MNDQkSx6ASv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def str2int_simple_encoder(df,columns='all'):\n",
        "  import pandas as pd\n",
        "  \n",
        "  id_dict = {}\n",
        "  if (columns=='all'):\n",
        "    \n",
        "    for i in df.columns:\n",
        "      if (df[i].dtype==object):\n",
        "        id_dict[i] = {}\n",
        "        unique_values = df[i].unique()\n",
        "        id_dict[i] = {name: id + 1 for id, name in enumerate(unique_values)}\n",
        "\n",
        "        df[i] = df[i].apply(lambda row, value : value[row], value = id_dict[i] )\n",
        "\n",
        "  else:\n",
        "    \n",
        "    for i in columns:\n",
        "      if ( (df[i].dtype==object) and (i in df.columns) ):\n",
        "        id_dict[i] = {}\n",
        "        unique_values = df[i].unique()\n",
        "        id_dict[i] = {name: id + 1 for id, name in enumerate(unique_values)}\n",
        "\n",
        "        df[i] = df[i].apply(lambda row, value : value[row], value = id_dict[i] )\n",
        "      else:\n",
        "        print('coluna especificada não é do tipo \"object\" ou não existe no dataframe')\n",
        "        return\n",
        "  \n",
        "  return id_dict"
      ],
      "metadata": {
        "id": "sC623raeAQvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#como era feito anteriormente:\n",
        "'''\n",
        "df = dados\n",
        "\n",
        "#Criar os dicionários para os valores únicos das colunas categóricas\n",
        "type_id = {}\n",
        "aux = df['type'].unique()\n",
        "for i in aux:\n",
        "  type_id[i] = np.where(aux==i)[0][0]+1\n",
        "print(type_id)\n",
        "\n",
        "#converter os valores categóricos da coluna \"type\" por numéricos\n",
        "df['type'] = df['type'].apply(lambda row, value : value[row],\n",
        "                                                    value = type_id )\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "NQ-4x_yBAqdL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "04815107-4c94-4467-efa4-8387b59cc3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndf = dados\\n\\n#Criar os dicionários para os valores únicos das colunas categóricas\\ntype_id = {}\\naux = df[\\'type\\'].unique()\\nfor i in aux:\\n  type_id[i] = np.where(aux==i)[0][0]+1\\nprint(type_id)\\n\\n#converter os valores categóricos da coluna \"type\" por numéricos\\ndf[\\'type\\'] = df[\\'type\\'].apply(lambda row, value : value[row],\\n                                                    value = type_id )\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##display_score(m,x_train,x_test,y_train,y_test))"
      ],
      "metadata": {
        "id": "OHgl4ej_o2wz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out-of-bag parameter:\n",
        "\n",
        "https://towardsdatascience.com/what-is-out-of-bag-oob-score-in-random-forest-a7fa23d710\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2020/12/out-of-bag-oob-score-in-the-random-forest-algorithm/\n",
        "\n",
        "https://stats.stackexchange.com/questions/88980/why-on-average-does-each-bootstrap-sample-contain-roughly-two-thirds-of-observat\n",
        "\n",
        "https://stats.stackexchange.com/questions/198839/evaluate-random-forest-oob-vs-cv"
      ],
      "metadata": {
        "id": "lgi1bQa7SxAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(v_real,v_pred): \n",
        "    return np.sqrt(sklearn.metrics.mean_squared_error(v_real,v_pred)) #leia sobre sklearn.metrics.mean_squared_error\n",
        "def r2(v_real,v_pred): \n",
        "    return sklearn.metrics.r2_score(v_real,v_pred) #leia sobre sklearn.metrics.r2_score\n",
        "\n",
        "##função para avaliar RMSE, R2 e OOB_score\n",
        "def display_score(m,x_train,x_test,y_train,y_test):\n",
        "    \n",
        "    res = [[rmse( y_train,m.predict(x_train) ), r2( y_train,m.predict(x_train) )],\n",
        "          [rmse( y_test,m.predict(x_test) ), r2( y_test,m.predict(x_test) )]] #a função display score irá retornar uma tabela\n",
        "    \n",
        "    score = pd.DataFrame(res, columns=['RMSE','R2'], index = ['Treino','Teste'])\n",
        "\n",
        "    if hasattr(m, 'oob_score_'): #https://www.programiz.com/python-programming/methods/built-in/hasattr\n",
        "        score.loc['OOB'] = [rmse(y_train, m.oob_prediction_), m.oob_score_]\n",
        "\n",
        "    display(score)"
      ],
      "metadata": {
        "id": "T5sUq8jfoPXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gráficos"
      ],
      "metadata": {
        "id": "6RzP6hKOX7wa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### plt_hist_by(df,variable,by)"
      ],
      "metadata": {
        "id": "QM6DjLSbYA9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plt_hist_by(df = pd.DataFrame(),\n",
        "                variable = [],\n",
        "                by = '',\n",
        "                consider_none = False,\n",
        "                consider_zeros = False):\n",
        "  #https://plotly.com/python/histograms/\n",
        "  import plotly.graph_objects as go\n",
        "\n",
        "  fig = go.Figure()\n",
        "\n",
        "  #Filtrar apenas as linha que possuem dados de \"variavel\"\n",
        "  for i in variable:\n",
        "    \n",
        "    if (consider_none==False):\n",
        "      df.loc[ df[i]=='none', i ] = np.nan\n",
        "      df.loc[ df[i]=='None', i ] = np.nan\n",
        "\n",
        "    if (consider_zeros==False):\n",
        "      df.loc[ df[i]==0, i ] = np.nan\n",
        "\n",
        "    df_aux = df.loc[ df[i].notna(), by]\n",
        "\n",
        "    fig.add_trace(go.Histogram(\n",
        "        x=df_aux,\n",
        "        histnorm='',\n",
        "        name=i, # name used in legend and hover labels\n",
        "        #marker_color='#EB89B5',\n",
        "        #opacity=0.75\n",
        "        ))\n",
        "\n",
        "  fig.update_layout(\n",
        "      title_text=f'Quantity of data by each {by}', # title of plot\n",
        "      xaxis_title_text=by, # xaxis label\n",
        "      yaxis_title_text='Count', # yaxis label\n",
        "      bargap=0.2, # gap between bars of adjacent location coordinates\n",
        "      bargroupgap=0.1 # gap between bars of the same location coordinates\n",
        "      )\n",
        "\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "Ub_A9LvesfM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### plt_hist_columns(df)"
      ],
      "metadata": {
        "id": "OwGZHhgGsi9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plt_hist_columns(df):\n",
        "  aux = []\n",
        "  for i in df.columns:\n",
        "    aux += [i]\n",
        "    if (len(aux)==4):\n",
        "      try:\n",
        "        df[aux] = df[aux].astype(float)\n",
        "      except:\n",
        "        print()\n",
        "      df[aux].hist()\n",
        "      aux = []\n",
        "  df[aux].hist()"
      ],
      "metadata": {
        "id": "JexNdshlsk3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### heatmap_corr(df, x='all', y='all')"
      ],
      "metadata": {
        "id": "hu87rosewxW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def heatmap_corr(df, x='all', y='all', method='pearson', min_periods=1, color='di'):\n",
        "  import pandas as pd\n",
        "  \n",
        "  corr_pear = df.corr( min_periods=min_periods, method=method )\n",
        "  \n",
        "  if (x=='all'):\n",
        "    x = corr_pear.columns.tolist()\n",
        "  #print(x)\n",
        "  if (y=='all'):\n",
        "    y = corr_pear.columns.tolist()\n",
        "  #print(y)\n",
        "  heatmap_pearson = pd.DataFrame( columns=x, index=y )\n",
        "  heatmap_pearson = corr_pear.loc[y,x]\n",
        "  \n",
        "    #GRAFICO#\n",
        "  f, ax = plt.subplots(figsize=( 1*len(x)+3, 1*len(y) ))\n",
        "  if color=='mono':\n",
        "    colors = ('#00076e', '#1b00ff', '#d0cbff', '#FFFFFF', '#d0cbff', '#1b00ff', '#00076e')\n",
        "  elif (color=='di'):\n",
        "    colors = ('#7e0000', '#ff0000', '#fecfcf', '#FFFFFF', '#d0cbff', '#1b00ff', '#00076e')\n",
        "  cmap = sns.blend_palette(colors, input='rgb', as_cmap=True)\n",
        "  sns.heatmap(heatmap_pearson, annot=True, cmap=cmap, ax=ax, center=0) \n",
        "\n",
        "  return heatmap_pearson"
      ],
      "metadata": {
        "id": "cXG76USmwu2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhlmbCW0tt1h"
      },
      "source": [
        "###draw_tree(t, dados, size=10, ratio=1, precision=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_tree(t, dados, size=10, ratio=1, precision=0):\n",
        "   \n",
        "    import re\n",
        "    import graphviz\n",
        "    import sklearn.tree\n",
        "    import IPython.display\n",
        "    \n",
        "    s=sklearn.tree.export_graphviz(t, out_file=None, feature_names=dados.columns, filled=True,\n",
        "                                   special_characters=True, rotate=True, precision=precision)\n",
        "    IPython.display.display(graphviz.Source(re.sub('Tree {',\n",
        "       f'Tree {{ size={size}; ratio={ratio}', s)))"
      ],
      "metadata": {
        "id": "HwlEYRr-kXia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###plotar_importancias(modelo, tags, n=10) - modelo RF"
      ],
      "metadata": {
        "id": "gqluL2em-ubQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotar_importancias(modelo, tags, n=10):\n",
        "    \n",
        "    fig, ax = plt.subplots(1,2, figsize = (20,4))\n",
        "\n",
        "    coefs = []\n",
        "    abs_coefs = []\n",
        "\n",
        "    if hasattr(modelo,'coef_'):\n",
        "        imp = modelo.coef_\n",
        "    elif hasattr(modelo,'feature_importances_'):\n",
        "        imp = modelo.feature_importances_\n",
        "    else:\n",
        "        print('sorry, nao vai rolar!')\n",
        "        return\n",
        "\n",
        "    coefs = (pd.Series(imp, index = tags))\n",
        "    coefs.plot(use_index=False, ax=ax[0]);\n",
        "    abs_coefs = (abs(coefs)/(abs(coefs).sum()))\n",
        "    abs_coefs.sort_values(ascending=False).plot(use_index=False, ax=ax[1],marker='.')\n",
        "\n",
        "    ax[0].set_title('Importâncias relativas das variáveis')\n",
        "    ax[1].set_title('Importâncias relativas das variáveis - ordem decrescente')\n",
        "\n",
        "    abs_coefs_df = pd.DataFrame(np.array(abs_coefs).T,\n",
        "                                columns = ['Importancias'],\n",
        "                                index = tags)\n",
        "\n",
        "    df = abs_coefs_df['Importancias'].sort_values(ascending=False)\n",
        "    \n",
        "    print(df.iloc[0:n])\n",
        "    plt.figure()\n",
        "    df.iloc[0:n].plot(kind='barh', figsize=(15,0.25*n), legend=False)\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "D-DlUSMwp5LG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}